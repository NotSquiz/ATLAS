# Building Adaptive AI Assistants: A State-of-the-Art Framework

AI assistants that dynamically adjust persona, tone, and guidance style based on detected user state represent the cutting edge of human-computer interaction as of January 2026. **The most effective implementations combine dimensional emotion models (valence-arousal-dominance), transformer-based detection (achieving 70-85% accuracy on basic emotions), hierarchical memory architectures like MemGPT, and evidence-based interaction modes drawn from Motivational Interviewing and cognitive scaffolding research.** This framework synthesizes peer-reviewed affective computing research, dialogue systems literature, and lessons from production deployments to provide actionable guidance for building adaptive AI systems.

The core insight from research is that user state exists on continuous dimensions rather than discrete categories, detection accuracy varies significantly by state type (valence is most reliably detected from text at 80-90%, while cognitive load requires multimodal signals), and effective adaptation requires matching five distinct interaction modes to detected states while gracefully handling uncertainty.

---

## State dimensions: what to track and why

Research over four decades consistently supports tracking user state across **six key dimensions**, each grounded in extensive empirical validation and practically detectable in conversational AI contexts.

### The core dimensional framework

**Emotional valence** (negative ↔ positive) emerges as the most reliably detectable dimension from text alone, with modern transformer models achieving **80-90% accuracy**. Russell's circumplex model (1980), with over 4,000 citations, established that all affective states can be mapped onto valence and arousal dimensions. The PAD model (Mehrabian & Russell, 1974) adds dominance—a user's sense of control—which proves critical for interactive contexts where users may feel helpless or empowered.

**Emotional arousal** (calm ↔ activated) captures energy and activation level independent of whether the emotion is positive or negative. High arousal combined with negative valence indicates states like frustration, anger, or anxiety; low arousal with negative valence indicates sadness or depletion. Detection accuracy for arousal from text alone drops to **65-80%** because arousal manifests more strongly in vocal and physiological signals than lexical choice.

**Cognitive load** (low ↔ high) draws from Sweller's Cognitive Load Theory, which identifies three types: intrinsic load from task complexity, extraneous load from poor design, and germane load from productive learning effort. Working memory holds approximately 7 chunks for 20 seconds, with only 2-4 chunks available for active processing. When users exhibit signs of overload, AI should reduce extraneous load by simplifying, chunking, and providing scaffolding.

| State Dimension | Detection Feasibility (Text-Only) | Primary Detection Approach |
|-----------------|-----------------------------------|---------------------------|
| **Emotional valence** | High (80-90%) | Sentiment models, fine-tuned LLMs |
| **Emotional arousal** | Medium (65-80%) | Lexical features, message patterns |
| **Cognitive load** | Medium-Low (55-70%) | Response coherence, question complexity |
| **Goal clarity** | High | Query specificity analysis |
| **Engagement** | Medium | Message length, response timing |
| **Receptivity** | Medium | Hedging, tone markers, question patterns |

**Goal clarity** (exploratory ↔ well-defined) determines whether users know what they want or are seeking direction. Detection relies on query specificity—vague questions like "tell me about X" versus precise requests with clear parameters. The adaptive generation framework from Janarthanam & Lemon (2014) uses reinforcement learning to dynamically adjust based on this dimension.

**Engagement** (disengaged ↔ deeply engaged) encompasses focused attention, felt involvement, and willingness to continue. Doherty & Doherty's (2018) five-phase engagement model—receptiveness → interest → evaluation → engagement → disengagement—provides a useful trajectory for tracking within sessions.

**Receptivity** (defensive ↔ open) captures whether users are guarded or open to input. This dimension determines appropriate approach: defensive users need rapport-building and demonstrated reliability before substantive engagement.

---

## Detection mechanisms: signals and algorithms

State detection relies on converging signals across linguistic markers, conversation dynamics, and—when available—multimodal inputs. Current state-of-the-art systems use **transformer-based models fine-tuned on emotion datasets**, with BERT-ERC (AAAI 2023) representing a paradigm shift by integrating contextual and structural information directly during fine-tuning rather than as separate steps.

### Linguistic markers that reliably indicate state

**Frustration signals** include repetition of problems ("still not working," "AGAIN"), intensifiers ("very," "extremely," "so"), emphatic punctuation (!!!, ???), decreasing message length over time, and imperative mood. Research on the GoEmotions dataset (Google, 2020)—58,000 Reddit comments labeled with 27 emotion categories—provides empirical grounding for these associations.

**Anxiety and uncertainty markers** involve increased hedging language: epistemic verbs ("suggest," "seem," "appear"), modal verbs ("may," "might," "could"), cognition verbs ("I think," "I believe," "I suppose"), and hypothetical constructions. Chan & Tan (2009) taxonomy identifies plausibility shields ("I think," "probably," "maybe") as the most common conversational hedges. Increased self-referential language (high "I" usage) correlates with depression and anxiety in LIWC research.

**Cognitive overload signals** include fragmented or incomplete sentences, topic switching, increased question frequency, explicit confusion markers, and longer response latency. Studies show that under high cognitive load, users produce shorter, more fragmented messages and make more requests for clarification.

**Engagement and positive state signals** manifest as longer, detailed messages; questions showing curiosity; elaboration with examples; and forward momentum in conversation. Users in flow states produce concise, task-focused messages with rapid back-and-forth exchanges and clear, specific requests.

### Conversation-level versus utterance-level detection

A critical insight from recent research: **conversation-level context dramatically improves detection accuracy**. Hierarchical BERT structures (F-BERT, H-BERT, ST-BERT) capture self-dependency (a speaker's own emotional trajectory), inter-speaker dependency (how speakers influence each other), and temporal emotional dynamics. Utterance-level analysis—treating each message in isolation—produces significantly worse results because the same words carry different meaning in different conversational contexts.

### Voice analysis features (when available)

For systems with audio input, prosodic features provide strong complementary signals:

- **Pitch (F0) and variability**: Excitement raises pitch; sadness lowers it
- **Speech rate**: Anxiety often increases rate; depression slows it
- **Pauses**: Increased pause length and frequency indicate cognitive load
- **Volume/intensity**: Anger increases volume; sadness decreases it
- **Voice quality (jitter, shimmer)**: Stress and fatigue markers

The MemoCMT cross-modal transformer achieves **81.33% unweighted accuracy on IEMOCAP** and **91.93% on ESD** by combining HuBERT audio embeddings with BERT text embeddings through attention-based fusion.

### Recommended detection architecture

For text-only systems, use **`j-hartmann/emotion-english-distilroberta-base`** (7 Ekman emotions + neutral, ~66% accuracy) as a primary classifier with conversation-level context tracking. Supplement with rule-based detection for frustration escalation patterns and explicit state markers. For edge deployment, **`boltuix/bert-emotion`** provides 13-emotion classification in approximately 20MB.

Track these behavioral signals at the conversation level:

- **Response latency changes** (increasing latency suggests cognitive load or disengagement)
- **Message length trajectory** (shortening often indicates frustration)
- **Question frequency changes** (increasing questions suggest confusion)
- **Topic coherence** (semantic similarity between turns; low coherence indicates scattered thinking)

---

## State persistence: temporal dynamics and memory

How long detected states persist, when to update estimates, and how to carry state across sessions represent critical architectural decisions. Research reveals substantial differences in persistence across state types.

### Duration patterns by state type

**Acute emotional states** have an intrinsic duration of seconds to minutes in their true physiological form, though Frijda et al. (1991) found that approximately 50% of participants reported emotions lasting over an hour. This discrepancy arises from *recurring emotion episodes*—being reminded of the triggering event repeatedly. Neural research (Heller et al., 2022) shows that emotional responses persist through sustained activity in underlying circuits, with self-transitions (staying in the same state) more probable than transitions to other states—implying emotional momentum.

**Cognitive load** fluctuates more rapidly, changing within seconds to minutes based on task complexity and working memory engagement. Block, Hancock & Zakay's (2010) meta-analysis confirms that cognitive load effects are more immediate than emotional states.

**Beliefs and preferences** decay slowly over days to weeks and typically require explicit user correction to update. **Persona traits** remain stable across sessions with minimal decay.

### Within-conversation state tracking algorithms

**Incremental Reasoning DST (ReDST)** models state tracking as a recursive process where current joint belief B_t relies on previous belief B_{t-1} and current turn belief Q_t through KEEP, UPDATE, and DELETE operations. This achieves state-of-the-art on MultiWOZ 2.1.

**Exponential recency-weighted averaging** provides a principled approach to weighting recent observations more heavily:

```
Q_n = α × r_n + (1-α) × Q_{n-1}
```

where α ∈ (0,1] controls decay rate. Higher α emphasizes recent observations; lower α provides more stability. For emotional state tracking, α values of **0.3-0.5** balance responsiveness with stability.

**Bayesian belief updating** maintains probability distributions over states: P(state|observation) ∝ P(observation|state) × P(state|history). Neural Belief Tracking (Mrkšić et al., 2017) uses pre-trained word vectors to produce distributed representations without hand-crafted lexicons.

### Cross-session memory architecture

The **MemGPT architecture** (Packer et al., 2023, UC Berkeley) provides the most sophisticated approach to long-term memory, inspired by operating system hierarchical memory:

- **Core Memory** (always-accessible): Essential facts, persona, key preferences—constrained by LLM token limits
- **Recall Memory** (searchable): Semantic search via vector embeddings for specific past interactions
- **Archival Memory** (long-term storage): Complete interaction history, paged in/out as needed

The LLM acts as its own memory manager through self-directed editing via tool calling, with strategic forgetting through summarization. The key innovation is transformation from episodic memory (specific time-bound experiences) to semantic memory (general knowledge detached from context) as interactions age.

### When to reset state assumptions

Implement multiple reset heuristics:

- **Time-based**: Reset transient emotional state after configurable idle period (24+ hours typical)
- **Session-based**: Clear momentary states at session boundary while preserving user model
- **Confidence-based**: Apply exponential decay to confidence; reset when below threshold
- **Contradiction-based**: Reset specific beliefs immediately upon explicit user correction
- **Topic-based**: Segment by topic; apply different decay rates per segment

The **cold start problem**—insufficient information to make inferences for new users—requires hybrid approaches: leverage user metadata when available, use default personas initially, employ explicit preference elicitation sparingly to avoid UX friction, and apply meta-learning to generalize from other users.

---

## Mode selection: matching interaction style to state

Research from Motivational Interviewing, cognitive scaffolding, and therapeutic conversation strongly supports **five distinct interaction modes**, each with evidence-based techniques and clear triggering conditions.

### Mode 1: Minimal/efficient

**Trigger:** User in flow state, focused, knows what they want—evidenced by concise task-focused messages, rapid exchanges, clear specific requests.

**Research foundation:** Csikszentmihalyi's flow theory establishes that interruptions destroy flow states. Studies show it takes **23 minutes on average** to return to original task after interruption, plus up to 30 minutes to return to full flow. The transient hypofrontality hypothesis (Dietrich, 2004) explains that flow involves downregulation of prefrontal cortices; external interruptions force re-engagement of explicit processing.

**Techniques:** Use brief, direct communication; minimize unsolicited elaboration; provide requested information without preamble; avoid clarifying questions unless essential; batch information efficiently rather than piece-by-piece.

### Mode 2: Structured/supportive

**Trigger:** User overwhelmed, scattered, high cognitive load—evidenced by long scattered messages, many topics, expressions of confusion, fragmented sentences.

**Research foundation:** Cognitive Load Theory (Sweller, 1988) establishes that working memory has limited capacity; when overloaded, information is lost. Wood, Bruner & Ross (1976) defined six scaffolding strategies including "reduction in degrees of freedom" and "frustration control."

**Techniques:** Break complex tasks into manageable steps; use phased instructions (overview first, then steps one at a time); offer templates and frameworks; limit new concepts introduced simultaneously; provide worked examples before independent problem-solving; use metaphors connecting to existing knowledge.

### Mode 3: Motivational/challenging

**Trigger:** User stuck, avoiding action, high ambivalence—evidenced by repeated same questions, procrastination language, "should" statements without action, low confidence in ability.

**Research foundation:** Motivational Interviewing (Miller & Rollnick, 4th edition 2023) provides the most empirically validated approach, with meta-analyses of 200+ randomized trials showing significant efficacy for behavior change. The OARS framework—Open questions, Affirmations, Reflective listening, Summarizing—operationalizes the approach.

**Techniques:** Elicit "change talk" through questions about desire, ability, reasons, and need ("How might you like things to be different?"); explore ambivalence without judgment; highlight discrepancy between current behavior and stated values; develop implementation intentions (specific action plans). **Critical:** Maintain collaborative partnership rather than authoritative directing; "roll with resistance" rather than confronting.

### Mode 4: Reflective/philosophical

**Trigger:** User seeking meaning, exploring values, contemplating life direction—evidenced by existential questions, values language, "what's the point" queries.

**Research foundation:** ICF Core Competencies (2025 framework) emphasize "evoking awareness" through powerful questioning. Socratic method (Beck & Dozois, 2011) uses carefully sequenced questions for guided discovery.

**Techniques:** Use open-ended questions with no yes/no answers; employ visionary questions ("What would your life look like if...?"); explore values alignment; ask perspective-taking questions ("What would you attempt if you knew you couldn't fail?"); provide space for reflection rather than immediate answers.

### Mode 5: Listening/validating

**Trigger:** User venting, processing emotions, seeking to be heard—evidenced by emotional expressions, frustration, sadness, storytelling without explicit questions.

**Research foundation:** Therapeutic alliance research shows relationship quality is one of the strongest predictors of treatment outcomes. Linehan's six levels of validation (DBT, 2015) provide a progression from active listening through radical genuineness.

**Techniques:** Reflect emotions heard ("You sound frustrated"); normalize experiences; use nonjudgmental language; avoid "fixing" prematurely; ask permission before offering solutions ("Would it be helpful if I suggested some options?"). **Critical insight:** Validation ≠ problem-solving. Premature solution-offering when users are venting feels dismissive and damages rapport.

### Mode-to-state mapping table

| User State Pattern | Primary Mode | Secondary Mode | Key Signals |
|-------------------|--------------|----------------|-------------|
| High arousal + negative valence + explicit complaint | Listening/Validating | Structured | Frustration markers, emotional language |
| Low engagement + scattered topics + question chains | Structured/Supportive | Listening | Confusion markers, fragmented messages |
| Clear goal + specific requests + rapid exchange | Minimal/Efficient | — | Task-focused, concise messages |
| Ambivalence + "should" language + inaction | Motivational/Challenging | Reflective | Procrastination markers, repeated questions |
| Values questions + meaning-seeking | Reflective/Philosophical | Listening | Existential framing, exploration language |
| Low arousal + negative valence + withdrawal | Listening/Validating | Supportive | Sadness markers, short disengaged responses |

### Mode transition principles

**Always start with listening**—assess user state before selecting mode. **Validate before challenging**—premature shift to motivational mode feels dismissive. **Match user's energy initially**, then gently guide toward helpful modes. Use **permission-based transitions**: "Would it be helpful if we broke this down into steps?" Watch for **mode mismatch signals**—user resistance often indicates wrong mode.

---

## Uncertainty handling: what to do when detection is ambiguous

Detection accuracy limitations—particularly for fine-grained emotions (GoEmotions baseline F1: 0.46) and cognitive states—require robust uncertainty handling.

### Confidence-based strategies

Implement **confidence thresholds** on detection outputs. When confidence falls below threshold (typically 0.6-0.7 for production systems), employ fallback strategies:

- **Confirmation requests**: "It sounds like you might be frustrated—is that right?"
- **Neutral defaults**: When uncertain, default to Listening/Validating mode (safest)
- **Multi-signal validation**: Require multiple signals to converge before high-confidence state assignment
- **Model ensembling**: Combine multiple detection approaches; agree-to-proceed, disagree-to-fallback

### Explicit preference elicitation

Ask users directly about their needs when appropriate: "Are you looking for suggestions, or would you prefer to talk through this first?" This respects user autonomy while gathering ground-truth signal.

### Graceful degradation hierarchy

1. **High confidence**: Apply detected state → select mode → adapt response
2. **Medium confidence**: Apply mode with softer adaptation; monitor for feedback
3. **Low confidence**: Default to neutral supportive mode; gather more signal
4. **Conflicting signals**: Ask clarifying question or use Listening mode

### Human escalation paths

Production mental health systems (Wysa, Ginger) maintain human therapist/coach escalation for cases where AI adaptation is insufficient. This pattern applies broadly: **always provide escalation paths** for high-stakes interactions.

---

## Key researchers and foundational works

### Affective computing foundations

**Rosalind Picard** (MIT Media Lab) founded the field with *Affective Computing* (MIT Press, 1997). Her work on emotion recognition from physiological signals led to Affectiva, now part of Smart Eye. **James A. Russell** (Boston College) established the circumplex model of affect (1980, 4000+ citations), demonstrating that valence and arousal capture the fundamental structure of emotional experience. **Albert Mehrabian** (UCLA) developed the PAD model (1974), adding dominance to valence-arousal. **Paul Ekman** (UCSF) created the basic emotions framework and FACS facial coding system, though recent research (Nature, 2023) critiques this as "too rigid." **Lisa Feldman Barrett** (Northeastern) provides the constructionist alternative, arguing emotions are constructed rather than innate categories.

### Dialogue systems and state tracking

**Steve Young and Blaise Thomson** (Cambridge) pioneered POMDP dialogue systems and Bayesian belief tracking. **Nikola Mrkšić** developed the Neural Belief Tracker, enabling data-driven state tracking without hand-crafted lexicons. **Charles Packer et al.** (UC Berkeley) created MemGPT (2023), the most sophisticated memory architecture for long-context agents.

### Therapeutic conversation and coaching

**William R. Miller and Stephen Rollnick** created Motivational Interviewing, now in its 4th edition (2023), with 200+ RCTs validating its efficacy. **Marsha Linehan** developed DBT and the six levels of validation framework. **Mihály Csíkszentmihályi** established flow theory. **John Sweller** developed Cognitive Load Theory with direct implications for AI scaffolding.

### Key recent surveys and papers

- Wang et al. (2022). "A systematic review on affective computing: emotion models, databases, and recent advances." *Information Fusion.* (400+ papers reviewed)
- Qin et al. (2023). "BERT-ERC: Fine-tuning BERT is Enough for Emotion Recognition in Conversation." *AAAI.*
- Demszky et al. (2020). "GoEmotions: A Dataset of Fine-Grained Emotions." *ACL.*
- Packer et al. (2023). "MemGPT: Towards LLMs as Operating Systems." *arXiv.*
- Maharana et al. (2024). "LOCOMO: Long-term Conversational Memory." *arXiv.*

---

## Commercial implementations and open-source tools

### Production systems

**Woebot Health** pioneered CBT-based therapeutic conversation with published RCTs showing non-inferiority to clinician-led therapy for teen depression. As of June 2025, it pivoted to B2B clinical partnerships. **Wysa** achieved FDA Breakthrough Device designation (2025) with engagement metrics showing 94% session completion among healthcare workers. **Replika** uses ongoing conversation memory and adaptive personas but has drawn criticism for over-affirmation without safety detection.

A significant gap exists between research and deployment: **none of the tested mental health bots asked about safety/risk even with concerning statements**, highlighting the importance of explicit safety-aware design.

### Open-source stack recommendations

**For emotion detection:**
- Primary: `j-hartmann/emotion-english-distilroberta-base` (Hugging Face)
- Edge/lightweight: `boltuix/bert-emotion` (~20MB)
- Libraries: `text2emotion` (5 basic emotions), `limbic` (Plutchik's wheel with negation handling)

**For dialogue management:**
- Full framework: **Rasa** (most mature, customizable NLU + dialogue management)
- Research: DeepPavlov (TensorFlow-based)
- Visual design: Botpress (non-developer friendly)

**For memory persistence:**
- Architecture pattern: MemGPT (hierarchical core/recall/archival memory)
- Vector storage: LanceDB, Pinecone, or Weaviate

---

## Conclusion: building adaptive AI that actually adapts

The research converges on several actionable principles. **Track six core dimensions** (valence, arousal, cognitive load, goal clarity, engagement, receptivity), but weight confidence by detection feasibility—valence from text is reliable; cognitive load requires multimodal signals or behavioral proxies. **Use conversation-level context**, not just utterance-level analysis—the BERT-ERC paradigm shows substantial improvement from integrating contextual information during model fine-tuning.

**Map states to five evidence-based modes** (Minimal, Structured, Motivational, Reflective, Listening) using the mode-to-state mapping table, with Listening/Validating as the safe default under uncertainty. **Implement hierarchical memory** following the MemGPT pattern: core facts always accessible, detailed history retrievable via semantic search, with principled decay and explicit reset triggers.

The most significant gap between research and deployment remains **safety detection**—production systems need explicit handling of concerning statements that current implementations miss. The second gap is cultural adaptation: most models train on Western data and underperform across diverse populations.

For teams building adaptive AI assistants, the recommended approach combines transformer-based emotion detection with Rasa-style dialogue management, MemGPT-inspired memory architecture, and mode selection logic drawn from Motivational Interviewing and scaffolding research. Start with high-confidence state detection before sophisticated adaptation—graceful degradation with explicit uncertainty handling produces better user experience than overconfident adaptation based on ambiguous signals.