# R30: Claude Agent SDK Masterclass - Complete Analysis

> **Source**: Claude Agent SDK Masterclass (112 minutes)
> **Speaker**: Tariq, Anthropic Agent SDK Team
> **Extracted**: January 2026
> **Purpose**: Inform ATLAS orchestrator development

---

## Executive Summary: 10 Key Insights for ATLAS

1. **"Bash is all you need"** [930s] - Bash tool beats custom tools. Composability, dynamic scripts, existing software access.

2. **Agent = Autonomy** [194s] - Agents "build their own context, decide their own trajectories." Different from workflows.

3. **Agent Loop** [1343s] - Gather context → Take action → Verify work. Three parts, loop until done.

4. **Verification Everywhere** [4928s] - "Verification can happen anywhere and should happen anywhere - put it in as many places as you can."

5. **Skills = Progressive Disclosure** [2001s] - Agent discovers capabilities by reading skill files on demand.

6. **Sub-Agents for Context Isolation** [4147s] - "Avoid context pollution. Start a new context session" for complex sub-tasks.

7. **Clear Context Often** [4575s] - Store state externally (git diff, files), clear context between tasks.

8. **Hooks Fight Hallucinations** [6596s] - Use deterministic hooks to enforce behavior (must read data, must write script).

9. **Design APIs for Agents** [3583s] - Use syntax agents know (SQL, ranges). Transform problems to be "in-distribution."

10. **Reversibility Matters** [4259s] - "How reversible is the work is a really good intuition" for agent success.

---

## 1. Core Philosophy

### Evolution of AI Features

| Stage | Description | Example | Timestamp |
|-------|-------------|---------|-----------|
| **Single LLM** | One-shot categorization | "categorize this email" | [138s] |
| **Workflow** | Structured pipeline | RAG + completion | [146s] |
| **Agent** | Autonomous, builds own context | Claude Code | [179s] |

> **[194s]** "Agents build their own context, decide their own trajectories, are working very very autonomously."

### When to Build an Agent

> **[1409-1420s]** "If you're thinking of building an agent, think about - can you verify its work? If you can verify its work, it's a great candidate for an agent."

> **[1245-1265s]** "If you're building something where you want to talk to it in natural language and take action flexibly - that's why you're building an agent."

### Why Claude Agent SDK

Built on Claude Code because Anthropic "kept rebuilding the same parts over and over again" [241s].

**Strong opinions baked in**:
- Bash is the most powerful agent tool
- File system for context engineering
- Skills for progressive disclosure
- Composability over rigid tool definitions

---

## 2. The Agent Loop

### Three-Part Structure [1343s]

```
┌─────────────────────────────────────────────────────┐
│                   AGENT LOOP                        │
├───────────────┬───────────────┬───────────────────┤
│  1. GATHER    │   2. ACTION   │    3. VERIFY      │
│   CONTEXT     │               │                   │
├───────────────┼───────────────┼───────────────────┤
│ • Grep files  │ • Code gen    │ • Lint/compile    │
│ • Search      │ • Bash exec   │ • Run tests       │
│ • Read docs   │ • API calls   │ • Schema check    │
│ • Query DB    │ • Write files │ • LLM critique    │
└───────────────┴───────────────┴───────────────────┘
         ↑                              │
         └──────────── LOOP ────────────┘
```

### Metalearning Process

> **[1319-1331s]** "The metalearning for designing an agent loop to me is just to read the transcripts over and over again. Every time you see the agent running, just read it and figure out - what is it doing? Why is it doing this? Can I help it out somehow?"

### ATLAS Implementation Status

| Step | Masterclass Teaching | ATLAS Current |
|------|---------------------|---------------|
| Gather | Grep, search, read | SkillLoader reads markdown |
| Action | Bash, codegen | SkillExecutor via CLI/API |
| Verify | Lint, test, schema | hooks.py post-execution only |

**Gap**: ATLAS lacks pre-execution and mid-execution verification.

---

## 3. Skills Architecture

### What Skills Are

> **[2200s-2220s]** "Skills are forms of progressive disclosure basically to the agent to figure out what it needs to do."

> **[2234s-2257s]** "Skills are an introduction into thinking about the file system as a way of storing context."

### Skill Structure

```
babybrains-os/
├── skills/
│   ├── draft_21s.md       # Skill spec (→ system prompt)
│   └── draft_60s.md
└── schemas/
    ├── draft_21s.out.v1.json  # Output schema
    └── draft_60s.out.v1.json
```

### Skill Discovery Pattern

> **[2458s-2506s]** "You just put it in the file system and you tell it 'here is a script, you can call it.' I would design all my CLI scripts to have --help so the model can call that and progressively disclose every subcommand."

### ATLAS Alignment

**ATLAS Implementation** (skill_executor.py:70-97):
```python
def load_skill(self, skill_name: str) -> str:
    """Load skill markdown content."""
    skill_file = self.skills_path / f"{skill_name}.md"
    return skill_file.read_text()  # Becomes system prompt
```

**Status**: ✅ Aligned with masterclass - skills are markdown files that become system prompts.

---

## 4. Sub-Agent Patterns

### When to Spawn Sub-Agents

> **[3969s-4010s]** "Sub-agents are a very important way of managing context. Sub-agents are great for when you need to do a lot of work and return an answer to the main agent."

### Context Isolation

> **[4147s-4161s]** "The main thing is to avoid context pollution. You probably wouldn't want to fork the context. You'd start a new context session and be like 'Hey, adversarially check the work of - this output was made by a junior analyst at McKinsey...'"

### Parallel Execution Pattern

```
Main Agent
├── [parallel] Sub-Agent 1: Read Sheet 1 → summary
├── [parallel] Sub-Agent 2: Read Sheet 2 → summary
├── [parallel] Sub-Agent 3: Read Sheet 3 → summary
│   [collect results]
├── Sub-Agent 4: Analyze summaries
└── Sub-Agent 5: Generate final report
```

### ATLAS Gap

**Current**: No sub-agent support
**Needed**: Parallel skill execution with context isolation

---

## 5. Hook & Verification Framework

### Verification Strategy Hierarchy

| Priority | Type | Example | Timestamp |
|----------|------|---------|-----------|
| 1 | **Rule-based** | Null checks, lint, compile | [4085s] |
| 2 | **Tool-based** | Read-before-write checks | [4085s] |
| 3 | **Sub-agent** | "Junior analyst" adversarial check | [4147s] |
| 4 | **LLM critique** | When rules insufficient | [4928s] |

### "Verification Everywhere"

> **[4928s]** "Verification can happen anywhere and should happen anywhere - put it in as many places as you can."

**Placement points**:
- After context gathering
- Before write operations
- After code generation
- After execution
- In hooks (pre/post)

### Hooks for Determinism

> **[6596s-6609s]** "Use hooks to fight against hallucinations - verify if agent returned response without writing a script. Use hooks to give feedback: 'please make sure you write a script, please make sure you read this data.'"

### ATLAS Current Implementation

**hooks.py** wraps existing validators:

```python
HOOKS = {
    "babybrains": {
        "qc_runner": {
            "cmd": ["python", "qc/qc_runner.py"],
            "blocking": True,
            "input_mode": "stdin",
            "block_codes": ["HOOK_FLAG_MISSING", "HOOK_TOO_LONG", ...]
        }
    }
}
```

**Gap**: Only post-execution verification. Need pre-execution hooks.

---

## 6. Context Engineering

### File System as Context

> **[308-317s]** "The file system is a way of context engineering."

> **[317-329s]** "One of the key insights we had through Claude Code was thinking a lot more through the context - not just a prompt, it's also the tools, the files and scripts that it can use."

### Progressive Loading

> **[4480s-4522s]** "You want to give it the starting amount of context. Like the first 10 rows and first 30 columns. You don't load all of it into context right away... The agent can navigate to these sheets, read them, keep a scratch pad, keep notes."

### Clear Context Often

> **[4575s-4598s]** "I tend to clear the context window very often. At least in code, the state is in the files of the codebase. Claude Code can just look at my git diff and be like 'oh hey these are the changes you made.' It doesn't need to know my entire chat history."

### Context Management Principles

1. **Never load entire dataset** - Start with samples
2. **Store state externally** - Files, git, database
3. **Clear often** - State lives outside context
4. **Use scratch pads** - Agent notes for navigation

---

## 7. Production Patterns

### Deployment Options

| Path | Infrastructure | Use Case |
|------|---------------|----------|
| **Local app** | User machine | Developer tools, CLI |
| **Sandbox** | Cloudflare | SaaS products |
| **Live dev server** | Sandbox + port | Interactive UI (Lovable) |

### What Anthropic Does Internally

1. **Git diff pattern** - Use git diff to reload context without full history
2. **Bash race conditions** - Invested heavily in solving (Adam Wolf's QCON talk)
3. **50-line agents** - Most agent code is boilerplate, actual logic is small
4. **Dogfooding** - "We dogfood Claude Code... we don't have custom [solutions]"

### Cost Management

> **[6340s-6376s]** "Agents are kind of pricey... focus on having the most intelligent models... rather charge fewer people more money. Find hard use cases... make sure you're solving a problem people want to pay for."

**Pricing models**:
- Subscription: Predictable, good for consistent usage
- Token-based: Variable, matches actual consumption
- Hybrid: Rate limits + usage-based (Claude Code model)

### Large Codebases

> **[6696s-6720s]** "Use good CLAUDE.md files, start in right directory, verification/hooks, don't rely on semantic search."

---

## 8. Tool Selection Matrix

| Method | Pros | Cons | Use For |
|--------|------|------|---------|
| **Tools** | Structured, reliable | High context, not composable | Atomic/destructive actions |
| **Bash** | Composable, flexible | Discovery latency | Dynamic, composable work |
| **Code Gen** | Highly dynamic | Longest execution | Data analysis, API composition |

**ATLAS Decision**:
- MCP tools for atomic ops (memory_store, workout_log)
- Bash for validator invocation
- Claude CLI for skill execution

---

## 9. Gap Analysis: ATLAS vs Masterclass

| Masterclass Teaching | ATLAS Current State | Status | Priority |
|---------------------|---------------------|--------|----------|
| Bash is all you need | skill_executor uses Claude CLI | ✅ Aligned | - |
| Skills = markdown → system prompt | Implemented in skill_executor.py | ✅ Aligned | - |
| Hooks for deterministic verification | hooks.py wraps validators | ✅ Aligned | - |
| File system as context | Skills loaded from file system | ✅ Aligned | - |
| **Sub-agents for context isolation** | Not implemented | ❌ Gap | High |
| **Clear context often (git diff)** | Not implemented | ❌ Gap | High |
| **Verification everywhere** | Post-execution only | ⚠️ Partial | High |
| **Adversarial checking** | Not implemented | ❌ Gap | Medium |
| **Progressive context loading** | Not implemented | ❌ Gap | Medium |
| **Scratch pad pattern** | Not implemented | ❌ Gap | Low |

---

## 10. Key Quotes Reference

### Philosophy
| Quote | Timestamp |
|-------|-----------|
| "Bash is all you need" | [930s] |
| "Agents build their own context, decide their own trajectories" | [194s] |
| "Context engineering, not just prompt engineering" | [317s] |
| "Can you verify its work? Great candidate for an agent." | [1409s] |

### Implementation
| Quote | Timestamp |
|-------|-----------|
| "Skills are progressive context disclosure" | [2001s] |
| "Sub-agents are a very important way of managing context" | [3969s] |
| "Avoid context pollution. Start a new context session." | [4147s] |
| "Verification everywhere" | [4928s] |

### Production
| Quote | Timestamp |
|-------|-----------|
| "I clear the context very often" | [4575s] |
| "Use hooks to fight hallucinations" | [6596s] |
| "Simple is not the same as easy" | [5040s] |
| "We dogfood Claude Code" | [6711s] |

---

## 11. Recommended Next Steps

### Priority 1: Verification Enhancement

**Current**: hooks.py only runs post-execution
**Add**:
1. Pre-execution hooks (check prerequisites)
2. Mid-execution hooks (validate intermediate state)
3. Adversarial sub-agent verification

### Priority 2: Sub-Agent Support

**Implementation**:
```python
class SubAgentExecutor:
    async def spawn(self, task: str, context: dict) -> SubAgentResult:
        """Spawn sub-agent with isolated context."""
        # New context session (no pollution)
        # Execute task
        # Return summarized result only
```

### Priority 3: Context Management

**Git Diff Pattern**:
```python
async def resume_session(self) -> dict:
    """Resume session using git diff instead of full history."""
    diff = subprocess.run(["git", "diff", "--stat"], capture_output=True)
    return {"changes": diff.stdout, "context": "minimal"}
```

### Priority 4: Session Compaction

**Implement context clearing with state preservation**:
- Store session state to file
- Clear context window
- Reload minimal context (git diff, current task)

### Priority 5: Progressive Loading

**For large skill chains**:
- Load skill headers first
- Load full skill on demand
- Keep scratch pad of completed steps

---

## Appendix: Section File References

Detailed extractions with verbatim quotes and timestamps:

- **Section 1**: [R30_Section1_Philosophy.md](./R30_Section1_Philosophy.md) (0-2400s)
  - Agent definition, agent loop, bash philosophy, context engineering

- **Section 2**: [R30_Section2_Implementation.md](./R30_Section2_Implementation.md) (2200-4600s)
  - Skills, sub-agents, hooks, state management, code patterns

- **Section 3**: [R30_Section3_Advanced.md](./R30_Section3_Advanced.md) (4400-6744s)
  - Q&A digest, verification strategies, production patterns

---

## Summary

ATLAS is well-aligned with core Claude Agent SDK patterns:
- Skills as markdown specs ✅
- Hooks for deterministic verification ✅
- CLI-first execution ✅

Key gaps to address:
1. **Sub-agent support** for parallel execution and context isolation
2. **Multi-point verification** (pre/mid/post execution)
3. **Context management** (clear often, git diff pattern)
4. **Adversarial checking** ("junior analyst" pattern)

The masterclass validates ATLAS's architecture while providing clear direction for next features.

---

*Document updated: 2026-01-07*
*Status: Complete analysis with section breakdowns*
*Related: R27.LangGraph integration with Claude Agent SDK*
