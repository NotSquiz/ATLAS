# External Knowledge APIs for AI Agents: January 2025 Assessment

Building ATLAS with the proposed stack of ref.tools, exa.ai, package registry APIs, and SQLite caching is technically feasible but **will likely exceed the $20/month budget**. A more cost-effective alternative uses Jina Reader (free tier) instead of ref.tools, which can bring total costs to **$15-20/month** while meeting all latency and token-efficiency requirements.

## Exa.ai delivers strong neural search with transparent pricing

Exa.ai offers semantic search optimized for code and technical content at **$5 per 1,000 searches** (1-25 results) plus **$1 per 1,000 pages** for text content retrieval. Rate limits of **5 queries per second** easily accommodate personal use, and their status page reports sub-350ms P50 latency for fast searches.

For code search specifically, Exa supports a `"github"` category filter that targets indexed repositories with neural embeddings rather than keyword matching. Token efficiency is controllable—you can request full text, AI-extracted highlights, or LLM-generated summaries, each billed at $1/1,000 pages. A "page" equals approximately 1,000 tokens.

**Cost estimate for 100 queries/day**: $0.50 (searches) + $0.10 (content) = **$18/month**

Main competitors include Tavily (~$100/month for 10k searches), Perplexity API ($100-200/month), Brave Search API (~$30/month), and Serper (~$100/month). Exa's pay-as-you-go model makes it the most cost-effective for low-volume personal use.

**Gotcha**: The $10 free starter credit covers roughly 2,000 searches—enough for 3 weeks of testing at moderate usage.

## Ref.tools reduces tokens dramatically but exceeds budget at scale

Ref.tools claims **60% average token reduction** compared to raw scraping, with some documentation queries achieving 95% fewer tokens. Their credit-based system prices at **$9/month for 1,000 credits** on the Basic plan, with 200 free starter credits.

The system covers thousands of public repositories and documentation sites including Firebase, Figma, and AWS. It uses intelligent chunking and a "dropout" mechanism that returns only the most relevant ~5,000 tokens per query. Example measurements show a single SEARCH query consuming ~54 credits and READ operations ~385 credits.

**Problem for your use case**: At 50-100 documentation queries/day with average ~3-5 credits per interaction, you'd need **$27-45/month**—well above budget. Rate limits aren't explicitly published, but guidance suggests budgeting ~20 tool calls per week per seat.

### Alternative: Jina Reader offers superior economics

Jina Reader provides **10 million free tokens** to new API keys with no credit card required. At 100 queries/day averaging 10,000 tokens output per query, the free tier lasts approximately **100 days**. After depletion, pricing runs approximately $0.02 per million tokens.

Rate limits with an API key: **500 requests per minute** for URL-to-Markdown conversion, **100 RPM** for search. The service converts web pages to clean Markdown using their ReaderLM-v2 model, strips boilerplate, deduplicates links, and captions images. PDF extraction and CSS selector targeting are included.

**Cost estimate**: $0-5/month depending on usage patterns. The Apache-2.0 license is corporate-friendly for any future commercialization.

### Firecrawl: Alternative for anti-bot handling

If you encounter sites with aggressive bot protection, Firecrawl's **$16/month Hobby plan** provides 3,000 credits with automatic proxy rotation and stealth mode. One credit equals one page; stealth proxy mode consumes up to 5 credits per request. This serves as a fallback when Jina Reader fails.

## GitHub code search cannot fully replace Exa.ai

GitHub's code search API has **severe rate limits**: only **10 requests per minute** for authenticated users, with no unauthenticated access since April 2023. Results cap at 1,000 per query, and the API uses legacy search syntax—newer web UI features like regex aren't available via API.

The API is **completely free** and supports powerful qualifiers: `repo:`, `org:`, `language:`, `path:`, `filename:`, plus boolean operators. For targeted searches within known repositories, it works well.

**Practical assessment**: GitHub works for specific, infrequent code pattern searches (cached aggressively), but the 10/minute limit makes it unsuitable as a primary code discovery mechanism. Implement exponential backoff—secondary rate limits can trigger even within primary limits. Consider a GitHub App if you need higher throughput (30 req/min per installation).

## Stack Overflow API remains accessible with important caveats

The free Stack Exchange API v2.3 offers **10,000 requests/day** with a registered API key (versus 300/day without). No restrictions exist on AI agents using the public API for search and retrieval.

However, **for AI training**, Stack Overflow now requires their commercial OverflowAPI product—partners include Google and OpenAI. For RAG-style retrieval in a personal assistant, the free API suffices.

Content falls under CC BY-SA licensing, requiring attribution. Heavy server-side caching means responses may not reflect immediate edits. No webhook support exists for real-time updates.

**Gotcha**: Register your application on Stack Apps immediately to get the 10k/day limit. Include a proper User-Agent header to avoid throttling.

## Package registries all support free, unauthenticated read access

| Registry | Rate Limit | Best Approach | Notes |
|----------|-----------|---------------|-------|
| **PyPI** | No explicit limit (CDN cached) | JSON API for metadata | Set descriptive User-Agent |
| **npm** | 5M requests/month acceptable | Registry API | Use abbreviated format for smaller responses |
| **crates.io** | **1 request/second** (API only) | Sparse index (`index.crates.io`) | **Mandatory User-Agent with contact info** |

For crates.io specifically, **use the sparse index** for version and dependency data—it has no rate limits. Reserve REST API calls for data not in the index (homepage URLs, repository links).

All three registries are rock-solid for 50-100 queries/day. No authentication required for read operations. ETag headers should be used for cache validation on PyPI and npm.

## Major documentation sites increasingly block AI crawlers

**Self-hosted DevDocs solves the access problem entirely**. DevDocs aggregates 100+ documentation sources into pre-scraped, normalized JSON. Run locally via Docker (`docker run -d -p 9292:9292 ghcr.io/freecodecamp/devdocs:latest`) for unlimited programmatic access.

ReadTheDocs offers a **public REST API v3** with 60 requests/minute authenticated (5/minute unauthenticated). The Embed API (`/api/v2/embed/`) retrieves HTML-formatted content from specific documentation pages.

For MDN, Python docs, and framework documentation, **clone the GitHub repositories** for local access—all maintain their documentation as open-source Markdown/RST files.

**Cloud provider docs pose the biggest challenge**: AWS uses WAF Bot Control, GCP and Azure employ similar anti-bot measures. As of 2023, 306 of the top 1,000 websites block GPTBot in robots.txt. Avoid scraping cloud provider documentation—use official CLI/SDK docs locally instead.

## Caching strategy delivers 75-85% hit rates at steady state

Recommended TTLs based on content volatility:

- **API documentation**: 48-72 hours (changes with releases)
- **Package metadata**: 4-6 hours (needs reasonable freshness)
- **Code examples**: 72 hours (rarely updated)
- **Stack Overflow answers**: 2-4 hours (can be edited)

SQLite is ideal for a personal AI agent—zero configuration, ACID-compliant, supports full-text search via FTS5, and handles this query volume trivially. Expected cache growth: **100-500MB** for a typical developer documentation set.

**Performance trajectory**: Cold start yields 0% hit rate. After one week of typical usage, expect **60-70%**. At steady state, **75-85%** hit rate is achievable, following Zipf distribution where ~20% of documentation serves ~80% of queries.

```python
CACHE_TTL_CONFIG = {
    'api_documentation': 48 * 3600,    # 48 hours
    'package_metadata': 4 * 3600,      # 4 hours  
    'code_examples': 72 * 3600,        # 72 hours
    'stackoverflow': 2 * 3600,         # 2 hours
}
```

## Realistic cost model for 50-100 queries/day

### Your proposed stack (ref.tools + exa.ai + direct APIs):
| Service | Monthly Cost |
|---------|-------------|
| Exa.ai (100 searches/day + content) | $15-20 |
| Ref.tools (Basic plan) | $9-27 |
| GitHub/Stack Overflow/Registries | Free |
| **Total** | **$24-47** |

### Budget-optimized alternative:
| Service | Monthly Cost |
|---------|-------------|
| Exa.ai (80 searches/day + content) | $12-15 |
| Jina Reader (free tier) | $0 |
| Firecrawl (on-demand fallback) | $0-5 |
| GitHub/Stack Overflow/Registries | Free |
| **Total** | **$12-20** |

The budget-optimized stack hits your **<$20/month** target by leveraging Jina Reader's generous free tier instead of ref.tools. Jina Reader's 10M free tokens provide approximately 3 months of documentation fetching before any cost accrues.

## Key gotchas for your AI agent implementation

- **Latency constraint (<500ms)**: Exa Fast achieves <350ms P50; Jina Reader averages 2.5s for search, 7.9s for full page reads—cache aggressively to meet your latency target
- **Token efficiency**: Exa and Jina both output Markdown; expect ~67% token reduction versus raw HTML
- **crates.io is the strictest**: Mandatory User-Agent with contact info, 1 req/sec limit—always use sparse index
- **GitHub secondary rate limits**: Can block requests even within primary limits based on usage patterns
- **Stack Overflow attribution**: CC BY-SA requires attribution; implement this in your agent's responses
- **Self-host DevDocs**: Eliminates the biggest documentation access headache entirely

## Conclusion

The optimal stack for ATLAS under budget constraints combines **Exa.ai** for semantic code/web search, **Jina Reader** for documentation conversion (replacing ref.tools), **self-hosted DevDocs** for aggregated framework documentation, **direct registry APIs** for package metadata, and **SQLite caching** with content-type-aware TTLs. This configuration meets the <$20/month budget, sub-500ms latency (with proper caching), and token-efficiency requirements while remaining lightweight enough for personal deployment.