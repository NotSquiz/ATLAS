# MCP servers on memory-constrained systems: A survival guide for 1GB

Claude Code natively supports MCP servers through built-in configuration commands, making memory-efficient MCP integration entirely viable within a **1GB budget**. The key is using the official MCP SDK (which includes FastMCP internally), consolidating tools into single-process servers, and implementing lazy-loading patterns. All proposed integrations—Google Calendar, Garmin Connect, and custom knowledge graphs—can run comfortably with **400-600MB combined**, leaving headroom for operations.

## Claude Code has full native MCP support

The critical discovery: **Claude Code (the CLI tool) fully supports MCP servers natively**. This eliminates any need for manual context injection workarounds.

**Adding MCP servers via CLI:**
```bash
# STDIO transport for local Python servers (recommended)
claude mcp add --transport stdio calendar -- python /path/to/calendar_mcp.py

# With environment variables
claude mcp add --transport stdio garmin --env GARMIN_EMAIL=you@email.com \
  --env GARMIN_PASSWORD=secret -- python /path/to/garmin_mcp.py

# HTTP transport for remote servers
claude mcp add --transport http github https://api.githubcopilot.com/mcp/
```

**Configuration file locations:**
- User/local servers: `~/.claude.json`
- Project-shared: `.mcp.json` in project root
- Settings: `~/.claude/settings.json`

**Project `.mcp.json` format:**
```json
{
  "mcpServers": {
    "calendar": {
      "type": "stdio",
      "command": "python",
      "args": ["-O", "/path/to/calendar_mcp.py"],
      "env": {
        "TOKEN_PATH": "/home/user/.tokens/google_token.json"
      }
    },
    "knowledge-graph": {
      "type": "stdio",
      "command": "python",
      "args": ["-O", "/path/to/kg_mcp.py"],
      "env": {
        "KG_DATA_PATH": "/path/to/knowledge_graph.yaml"
      }
    }
  }
}
```

Use `/mcp` inside a Claude Code session to check server status and trigger OAuth flows.

## The official MCP SDK beats standalone FastMCP for constrained systems

The official MCP Python SDK (`pip install mcp`) **already includes FastMCP** internally as `mcp.server.fastmcp`. This provides the same decorator-based API with fewer dependencies than standalone FastMCP 2.0.

| Package | Base Memory | Dependencies | Best For |
|---------|-------------|--------------|----------|
| `mcp` (official SDK) | **30-50MB** | Minimal core | Memory-constrained ✅ |
| `fastmcp` (v2.0) | 50-80MB | OAuth, CLI, OpenAPI | Full-featured production |

**Minimal MCP server template (~10 lines):**
```python
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("MyTools")

@mcp.tool()
def my_tool(arg: str) -> str:
    """Tool description for LLM routing."""
    return f"Result: {arg}"

if __name__ == "__main__":
    mcp.run()  # STDIO transport by default
```

**Transport memory comparison:**
- **STDIO**: ~5-10MB overhead, no network stack—**use this for all local servers**
- **HTTP/SSE**: ~30-50MB additional (uvicorn/starlette)—only for remote access

**Critical optimization**: Consolidate multiple tools into **one server process**. Each additional Python process costs ~25-30MB base overhead, but additional tools within a process cost only ~0.5-1MB each.

## Google Calendar MCP: 40-80MB with Python implementation

Multiple Python implementations exist. For maximum memory efficiency, use either the minimal `rsc1102/Google_Calendar_MCP` or build a custom server.

**Memory footprints:**
| Implementation | Language | Memory |
|---------------|----------|--------|
| DIY minimal Python | Python | **25-50MB** ✅ |
| rsc1102/Google_Calendar_MCP | Python | 40-80MB |
| nspady/google-calendar-mcp | Node.js | 80-150MB |

**Complete lightweight Calendar MCP server:**
```python
#!/usr/bin/env python3
"""Lightweight Google Calendar MCP Server - ~40MB"""
import os
import datetime
from mcp.server.fastmcp import FastMCP
from google.oauth2.credentials import Credentials
from google.auth.transport.requests import Request
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build

SCOPES = ["https://www.googleapis.com/auth/calendar"]
mcp = FastMCP("google-calendar")
_service = None

def get_calendar_service():
    global _service
    if _service:
        return _service
    
    creds = None
    token_path = os.environ.get("TOKEN_PATH", "token.json")
    creds_path = os.environ.get("CREDENTIALS_PATH", "credentials.json")
    
    if os.path.exists(token_path):
        creds = Credentials.from_authorized_user_file(token_path, SCOPES)
    
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(creds_path, SCOPES)
            creds = flow.run_local_server(port=0)
        with open(token_path, "w") as f:
            f.write(creds.to_json())
    
    _service = build("calendar", "v3", credentials=creds)
    return _service

@mcp.tool()
def list_events(max_results: int = 10, days_ahead: int = 7) -> str:
    """List upcoming calendar events."""
    service = get_calendar_service()
    now = datetime.datetime.utcnow().isoformat() + "Z"
    end = (datetime.datetime.utcnow() + datetime.timedelta(days=days_ahead)).isoformat() + "Z"
    
    events = service.events().list(
        calendarId="primary", timeMin=now, timeMax=end,
        maxResults=max_results, singleEvents=True, orderBy="startTime",
        fields="items(id,summary,start,end,location)"
    ).execute().get("items", [])
    
    return "\n".join([
        f"• {e['summary']} - {e['start'].get('dateTime', e['start'].get('date'))}"
        for e in events
    ]) or "No upcoming events."

@mcp.tool()
def create_event(summary: str, start_time: str, end_time: str, 
                 description: str = "", location: str = "") -> str:
    """Create calendar event. Times in ISO format (2024-01-15T14:00:00)."""
    service = get_calendar_service()
    event = {
        "summary": summary, "description": description, "location": location,
        "start": {"dateTime": start_time, "timeZone": "UTC"},
        "end": {"dateTime": end_time, "timeZone": "UTC"},
    }
    created = service.events().insert(calendarId="primary", body=event).execute()
    return f"Created: {created.get('htmlLink')}"

if __name__ == "__main__":
    mcp.run()
```

**OAuth setup for single-user:**
1. Create OAuth credentials in Google Cloud Console (Desktop app type)
2. Download `credentials.json` 
3. **Publish app to "Production"** to avoid 7-day token expiry
4. Run server once to complete OAuth flow, generates `token.json`
5. Tokens auto-refresh—no repeated logins needed

**Dependencies:** `pip install google-api-python-client google-auth-oauthlib mcp`

## Garmin Connect MCP: Authentication tokens last 1 year

The `garminconnect` Python library provides access to all health metrics via Garmin's unofficial API. Key insight: **OAuth1 tokens survive for 1 year**, eliminating frequent re-authentication.

**Available data types:**
- **Sleep**: duration, stages (deep/light/REM), sleep score, SpO2, sleep stress
- **HRV**: daily average, weekly baseline, status (balanced/unbalanced)
- **Heart Rate**: resting HR, daily HR ranges, HR zones
- **Stress**: all-day stress levels, body battery
- **Activities**: runs, walks, cycling with GPS, splits, pace
- **Body Composition**: weight, body fat %, muscle mass, BMI

**Minimal Garmin MCP server (~60MB):**
```python
#!/usr/bin/env python3
"""Garmin Connect MCP Server with token persistence"""
import os
import json
from datetime import date
from pathlib import Path
from mcp.server.fastmcp import FastMCP
from garminconnect import Garmin

mcp = FastMCP("garmin-health")
TOKEN_DIR = Path(os.environ.get("GARMIN_TOKEN_DIR", "~/.garminconnect")).expanduser()
_api = None

def get_api():
    global _api
    if _api:
        return _api
    
    _api = Garmin()
    
    # Try resuming from saved tokens (lasts 1 year!)
    if TOKEN_DIR.exists():
        try:
            _api.garth.resume(str(TOKEN_DIR))
            return _api
        except Exception:
            pass
    
    # Fall back to credentials login
    _api = Garmin(os.environ["GARMIN_EMAIL"], os.environ["GARMIN_PASSWORD"])
    _api.login()
    TOKEN_DIR.mkdir(exist_ok=True)
    _api.garth.save(str(TOKEN_DIR))
    return _api

@mcp.tool()
def get_sleep_data(date_str: str = "") -> str:
    """Get sleep data for a date (YYYY-MM-DD, defaults to today)."""
    api = get_api()
    target = date_str or date.today().isoformat()
    sleep = api.get_sleep_data(target)
    
    daily = sleep.get("dailySleepDTO", {})
    return json.dumps({
        "date": daily.get("calendarDate"),
        "total_sleep_seconds": daily.get("sleepTimeSeconds"),
        "deep_sleep_seconds": daily.get("deepSleepSeconds"),
        "light_sleep_seconds": daily.get("lightSleepSeconds"),
        "rem_sleep_seconds": daily.get("remSleepSeconds"),
        "sleep_score": daily.get("sleepScores", {}).get("overall", {}).get("value"),
    }, indent=2)

@mcp.tool()
def get_hrv_data(date_str: str = "") -> str:
    """Get HRV (heart rate variability) data for a date."""
    api = get_api()
    target = date_str or date.today().isoformat()
    return json.dumps(api.get_hrv_data(target), indent=2)

@mcp.tool()
def get_stress_data(date_str: str = "") -> str:
    """Get stress levels and body battery for a date."""
    api = get_api()
    target = date_str or date.today().isoformat()
    return json.dumps(api.get_stress_data(target), indent=2)

@mcp.tool()
def get_recent_activities(count: int = 5) -> str:
    """Get recent activities (runs, walks, etc)."""
    api = get_api()
    activities = api.get_activities(0, count)
    return json.dumps([{
        "name": a.get("activityName"),
        "type": a.get("activityType", {}).get("typeKey"),
        "date": a.get("startTimeLocal"),
        "duration_minutes": round(a.get("duration", 0) / 60),
        "distance_km": round(a.get("distance", 0) / 1000, 2),
        "calories": a.get("calories"),
    } for a in activities], indent=2)

if __name__ == "__main__":
    mcp.run()
```

**Caching strategy for rate limiting protection:**
```python
import sqlite3
from datetime import datetime, timedelta

class GarminCache:
    def __init__(self, db_path="garmin_cache.db"):
        self.conn = sqlite3.connect(db_path)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS cache (
                key TEXT PRIMARY KEY,
                data TEXT,
                fetched_at TIMESTAMP
            )
        """)
    
    def get_or_fetch(self, key: str, fetch_fn, ttl_hours: int = 6):
        row = self.conn.execute(
            "SELECT data, fetched_at FROM cache WHERE key = ?", (key,)
        ).fetchone()
        
        if row:
            data, fetched = row
            if datetime.now() - datetime.fromisoformat(fetched) < timedelta(hours=ttl_hours):
                return json.loads(data)
        
        result = fetch_fn()
        self.conn.execute(
            "INSERT OR REPLACE INTO cache VALUES (?, ?, ?)",
            (key, json.dumps(result), datetime.now().isoformat())
        )
        self.conn.commit()
        return result
```

**Dependencies:** `pip install garminconnect mcp`

## Custom knowledge graph MCP without a graph database

An in-memory YAML-based knowledge graph runs efficiently under **100MB** for 10,000+ entities using simple Python data structures with indexing.

**Complete knowledge graph MCP server:**
```python
#!/usr/bin/env python3
"""Memory-efficient Knowledge Graph MCP Server (~80MB for 10k entities)"""
from mcp.server.fastmcp import FastMCP
from typing import Optional, List, Dict, Any
from dataclasses import dataclass, field
from collections import defaultdict, deque
import yaml
import os

mcp = FastMCP(
    "knowledge-graph",
    instructions="Query entities and relationships. Use search_entities to find, "
                 "get_relationships to explore connections, traverse_path for paths."
)

@dataclass
class Entity:
    id: str
    type: str
    properties: Dict[str, Any] = field(default_factory=dict)

@dataclass
class Relationship:
    source: str
    target: str
    type: str
    properties: Dict[str, Any] = field(default_factory=dict)

class InMemoryKnowledgeGraph:
    def __init__(self):
        self.entities: Dict[str, Entity] = {}
        self.relationships: List[Relationship] = []
        self._outgoing: Dict[str, List[int]] = defaultdict(list)
        self._incoming: Dict[str, List[int]] = defaultdict(list)
        self._by_type: Dict[str, List[str]] = defaultdict(list)
        self._text_index: Dict[str, set] = defaultdict(set)
    
    def load_yaml(self, path: str):
        with open(path) as f:
            data = yaml.safe_load(f)
        for e in data.get("entities", []):
            self.add_entity(Entity(**e))
        for r in data.get("relationships", []):
            self.add_relationship(Relationship(**r))
    
    def add_entity(self, entity: Entity):
        self.entities[entity.id] = entity
        self._by_type[entity.type].append(entity.id)
        for v in entity.properties.values():
            if isinstance(v, str):
                for word in v.lower().split():
                    self._text_index[word].add(entity.id)
    
    def add_relationship(self, rel: Relationship):
        idx = len(self.relationships)
        self.relationships.append(rel)
        self._outgoing[rel.source].append(idx)
        self._incoming[rel.target].append(idx)
    
    def search(self, query: str, entity_type: str = None, limit: int = 10) -> List[Entity]:
        candidates = set()
        for word in query.lower().split():
            candidates.update(self._text_index.get(word, set()))
        if entity_type:
            candidates &= set(self._by_type.get(entity_type, []))
        return [self.entities[eid] for eid in list(candidates)[:limit] if eid in self.entities]
    
    def get_neighbors(self, entity_id: str, direction: str = "both") -> List[Dict]:
        neighbors = []
        if direction in ("out", "both"):
            for idx in self._outgoing.get(entity_id, []):
                rel = self.relationships[idx]
                neighbors.append({"entity_id": rel.target, "rel_type": rel.type, "dir": "out"})
        if direction in ("in", "both"):
            for idx in self._incoming.get(entity_id, []):
                rel = self.relationships[idx]
                neighbors.append({"entity_id": rel.source, "rel_type": rel.type, "dir": "in"})
        return neighbors
    
    def find_path(self, start: str, end: str, max_depth: int = 4) -> Optional[List[str]]:
        if start not in self.entities or end not in self.entities:
            return None
        queue = deque([(start, [start])])
        visited = {start}
        while queue:
            current, path = queue.popleft()
            if current == end:
                return path
            if len(path) >= max_depth:
                continue
            for idx in self._outgoing.get(current, []) + self._incoming.get(current, []):
                rel = self.relationships[idx]
                neighbor = rel.target if rel.source == current else rel.source
                if neighbor not in visited:
                    visited.add(neighbor)
                    queue.append((neighbor, path + [neighbor]))
        return None

kg = InMemoryKnowledgeGraph()

@mcp.tool()
def search_entities(query: str, entity_type: str = None, limit: int = 10) -> List[Dict]:
    """Search knowledge graph by text. Use keywords, not full sentences."""
    results = kg.search(query, entity_type, limit)
    return [{"id": e.id, "type": e.type, "properties": e.properties} for e in results]

@mcp.tool()
def get_relationships(entity_id: str, direction: str = "both") -> List[Dict]:
    """Get relationships for entity. direction: 'in', 'out', or 'both'."""
    return kg.get_neighbors(entity_id, direction)

@mcp.tool()
def traverse_path(start_entity: str, end_entity: str, max_hops: int = 4) -> Dict:
    """Find shortest path between two entities."""
    path = kg.find_path(start_entity, end_entity, max_hops)
    if path:
        return {"found": True, "path": path, "hops": len(path) - 1}
    return {"found": False, "message": "No path within max_hops"}

@mcp.tool()
def get_entity(entity_id: str) -> Dict:
    """Get complete details for a specific entity by ID."""
    e = kg.entities.get(entity_id)
    if not e:
        return {"error": f"Entity '{entity_id}' not found"}
    return {"id": e.id, "type": e.type, "properties": e.properties,
            "relationship_count": len(kg._outgoing.get(entity_id, [])) + len(kg._incoming.get(entity_id, []))}

if __name__ == "__main__":
    data_path = os.environ.get("KG_DATA_PATH", "knowledge_graph.yaml")
    if os.path.exists(data_path):
        kg.load_yaml(data_path)
    mcp.run()
```

**YAML data format:**
```yaml
# knowledge_graph.yaml
entities:
  - id: "project-atlas"
    type: "Project"
    properties:
      name: "ATLAS"
      description: "Personal knowledge management system"
      status: "active"
  
  - id: "person-user"
    type: "Person"
    properties:
      name: "User"
      role: "Developer"

relationships:
  - source: "person-user"
    target: "project-atlas"
    type: "OWNS"
    properties:
      since: "2024-01"
```

**Tool descriptions that improve LLM routing:**
```python
@mcp.tool()
def search_entities(query: str, entity_type: str = None) -> List[Dict]:
    """Search knowledge graph by text keywords.
    
    USE THIS WHEN: Finding entities by name/description, starting exploration
    DO NOT USE WHEN: You already have an entity ID (use get_entity instead)
    
    Examples:
      search_entities("ATLAS project") → finds project entities
      search_entities("developer", entity_type="Person") → finds people
    """
```

## Memory budget allocation for sub-1GB operation

With careful architecture, **all integrations fit comfortably within 600MB**, leaving 400MB headroom.

**Recommended allocation:**

| Component | Memory | Strategy |
|-----------|--------|----------|
| Calendar MCP | **50MB** | Persistent, frequent use |
| Garmin MCP | **60MB** | Lazy-load, cache to SQLite |
| Knowledge Graph MCP | **100MB** | Lazy-load, 5-min idle timeout |
| Combined Core Tools | **100MB** | Merge all above into one server |
| **Buffer/headroom** | **400MB** | GC, temp allocations, spikes |
| **Total** | **600-700MB** | Well under 1GB ✅ |

**Ultimate memory saver—consolidate into one server:**
```python
# unified_mcp_server.py - All tools in one ~150MB process
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("atlas-unified")

# Calendar tools
@mcp.tool()
def list_calendar_events(...): ...

@mcp.tool()
def create_calendar_event(...): ...

# Garmin tools
@mcp.tool()
def get_sleep_data(...): ...

@mcp.tool()
def get_hrv_data(...): ...

# Knowledge graph tools
@mcp.tool()
def search_entities(...): ...

@mcp.tool()
def get_relationships(...): ...

if __name__ == "__main__":
    mcp.run()
```

**Lazy loading with idle timeout:**
```python
import sys
from threading import Timer

class IdleShutdown:
    def __init__(self, timeout_sec=300):
        self.timeout = timeout_sec
        self.timer = None
    
    def reset(self):
        if self.timer:
            self.timer.cancel()
        self.timer = Timer(self.timeout, lambda: sys.exit(0))
        self.timer.daemon = True
        self.timer.start()

idle = IdleShutdown(300)  # 5-minute timeout

@mcp.tool()
def my_tool(arg: str) -> str:
    idle.reset()  # Reset on every call
    return f"Result: {arg}"
```

**Memory limits without Docker (WSL2/Linux):**
```bash
# Using systemd-run
systemd-run --user --scope -p MemoryMax=150M python -O mcp_server.py

# Using Python resource module
import resource
resource.setrlimit(resource.RLIMIT_AS, (150*1024*1024, 150*1024*1024))
```

## Viability assessment and final recommendations

| Integration | Viable? | Memory | Recommendation |
|------------|---------|--------|----------------|
| **Google Calendar** | ✅ Yes | 40-50MB | DIY Python server, cache events |
| **Garmin Connect** | ✅ Yes | 50-60MB | Use token persistence, SQLite cache |
| **Knowledge Graph** | ✅ Yes | 80-100MB | In-memory YAML, lazy-load |
| **Combined unified** | ✅ Yes | **150MB** | Best option for survival mode |

**Key survival mode strategies:**

1. **Use official MCP SDK** (`pip install mcp`)—lighter than standalone FastMCP
2. **STDIO transport only**—no HTTP stack overhead
3. **Single multi-tool server**—consolidate all tools to avoid per-process overhead
4. **Lazy initialization**—don't connect to APIs until first tool call
5. **Token persistence**—Google tokens refresh automatically, Garmin tokens last 1 year
6. **SQLite caching**—reduce API calls, especially for Garmin (rate limited)
7. **Idle timeouts**—auto-terminate unused servers after 5 minutes
8. **Python optimization flags**—`python -O` removes docstrings/asserts

**Claude Code configuration for your setup:**
```json
{
  "mcpServers": {
    "atlas": {
      "type": "stdio",
      "command": "python",
      "args": ["-O", "/path/to/unified_mcp_server.py"],
      "env": {
        "PYTHONOPTIMIZE": "2",
        "GOOGLE_TOKEN_PATH": "~/.tokens/google.json",
        "GARMIN_TOKEN_DIR": "~/.garminconnect",
        "KG_DATA_PATH": "~/.atlas/knowledge_graph.yaml"
      }
    }
  }
}
```

This architecture delivers full functionality—calendar management, health metrics tracking, and knowledge graph queries—within your **1GB constraint** with comfortable headroom for stable operation.